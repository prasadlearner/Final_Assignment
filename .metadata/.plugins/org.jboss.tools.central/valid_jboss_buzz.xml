<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title type="html">How to run standalone Jakarta Batch Jobs</title><link rel="alternate" href="https://www.mastertheboss.com/java-ee/batch-api/running-batch-jobs-in-j2se-applications/" /><author><name>F.Marchioni</name></author><id>https://www.mastertheboss.com/java-ee/batch-api/running-batch-jobs-in-j2se-applications/</id><updated>2023-07-14T10:16:48Z</updated><content type="html">Jakarta Batch, formerly known as Java Batch, is a specification that provides a standardized approach for implementing batch processing in Java applications. It offers a robust and scalable framework for executing large-scale, long-running, and data-intensive tasks. In this tutorial, we will explore the process of running Jakarta Batch Jobs as standalone Java applications, discussing the ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>A developer’s path to success with OpenShift and containers</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/07/13/developers-path-success-openshift-and-containers" /><author><name>Valentina Rodriguez Sosa</name></author><id>e01ea10c-6333-49c0-8681-48b4641c4ebe</id><updated>2023-07-13T07:00:00Z</updated><published>2023-07-13T07:00:00Z</published><summary type="html">&lt;p&gt;I am a developer new to containers, Kubernetes, or CI/CD. Where should I start?&lt;/p&gt; &lt;p&gt;This article provides five pathways including resources to succeed on your container journey.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Highlighted material:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;The following materials are free with no prerequisites.&lt;/li&gt; &lt;li aria-level="1"&gt;These materials are foundational for you to start working on your next project ASAP.&lt;/li&gt; &lt;li aria-level="1"&gt;Training materials will take up to five hours to complete.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;1. Start building your skills with containers and OpenShift&lt;/h2&gt; &lt;p&gt;To start with containers, understand what containers are and how CI/CD can automate the software development lifecycle. &lt;/p&gt; &lt;ul&gt;&lt;li aria-level="2"&gt;Documentation: &lt;a href="https://www.redhat.com/en/topics/containers#overview"&gt;Understanding containers &lt;/a&gt;&lt;/li&gt; &lt;li aria-level="2"&gt;Blog: &lt;a href="https://developers.redhat.com/blog/2020/09/03/the-present-and-future-of-ci-cd-with-gitops-on-red-hat-openshift#"&gt;The present and future of CI/CD with GitOps on Red Hat OpenShift &lt;/a&gt;&lt;/li&gt; &lt;li aria-level="2"&gt;Documentation: &lt;a href="https://www.redhat.com/en/topics/cloud-native-apps"&gt;Understanding Cloud Native Applications&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Start building your skills&lt;/h3&gt; &lt;p&gt;Gather hands-on experience with video tutorials and learning paths to practice the concepts learned from foundational to advanced on OpenShift.&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="2"&gt;Video tutorial: &lt;a href="https://developers.redhat.com/learn/openshift/foundations-openshift"&gt;Foundations of OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="2"&gt;Video tutorial: &lt;a href="https://developers.redhat.com/learn/openshift"&gt;OpenShift and Kubernetes learning&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="2"&gt;Try the Developer Sandbox for Red Hat OpenShift: &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Start exploring in the Developer Sandbox for free&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Learn more about Kubernetes&lt;/h3&gt; &lt;p&gt;A deep dive on Kubernetes concepts from services to containers and pods: &lt;/p&gt; &lt;ul&gt;&lt;li&gt;Article: &lt;a href="https://developers.redhat.com/articles/2023/04/05/kubernetes-patterns-path-cloud-native"&gt;Kubernetes Patterns: The path to cloud native&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Our product documentation&lt;/h3&gt; &lt;p&gt;Discover all the features and capabilities of OpenShift from our product documentation.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.13/openshift_images/index.html"&gt;Overview of Images in Red Hat OpenShift &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.13/applications/index.html"&gt;Building Applications with Red Hat OpenShift &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.13/web_console/web-console-overview.html"&gt;OpenShift Web Console Overview&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;2. Modernize your applications&lt;/h2&gt; &lt;p&gt;Explore the practices to move your application to containers.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Video tutorial and additional materials: &lt;a href="https://developers.redhat.com/topics/microservices"&gt;Developing microservices on Kubernetes&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Documentation: &lt;a href="https://www.redhat.com/en/topics/application-modernization/what-is-dotnet-modernization#:~:text=The%20purpose%20of%20workload%20modernization,and%20integrating%20old%20with%20new."&gt;What is .NET application modernization?&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Article: &lt;a href="https://developers.redhat.com/articles/2023/05/15/how-use-new-openshift-quick-starts-deploy-jboss-eap"&gt;OpenShift QuickStarts to deploy JBossEAP&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Ready to practice?&lt;/h3&gt; &lt;p&gt;Practice the concepts learn with our Developer Sandbox for Red Hat OpenShift, tutorials, and hands-on labs.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Tutorials: &lt;a href="https://developers.redhat.com/topics"&gt;All Development topics with Red Hat Developer &lt;/a&gt;&lt;/li&gt; &lt;li&gt;Video tutorial: &lt;a href="https://www.redhat.com/en/services/training/do092-developing-cloud-native-applications-microservices-architectures"&gt;Developing cloud-native applications with microservices&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Hands-on lab: &lt;a href="https://developers.redhat.com/learn/openshift/develop-on-openshift"&gt;Developing on OpenShift&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Learn more about application development&lt;/h3&gt; &lt;p&gt;Learn about Red Hat Enterprise Linux capabilities to improve the developer experience and container applications development experience.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Article: &lt;a href="https://developers.redhat.com/articles/2023/05/10/how-new-rhel-92-improves-developer-experience#"&gt;How the new RHEL 9.2 improves the developer experience &lt;/a&gt;&lt;/li&gt; &lt;li&gt;Article: &lt;a href="https://developers.redhat.com/articles/2022/12/12/kubernetes-native-inner-loop-development-quarkus"&gt;Kubernetes-native inner loop development with Quarkus&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;3. Migrate at scale with OpenShift&lt;/h2&gt; &lt;p&gt;After migrating a couple of applications, you might wonder how we can replicate this process across an organization. Discover where to start with the modernization journey and how the developer experience can be improved.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Demo video: &lt;a href="https://www.youtube.com/watch?v=Pe0bFA4WawQ"&gt;Build, test, tune, and deploy your application with Red Hat OpenShift Dev Spaces&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Article: &lt;a href="https://developers.redhat.com/articles/2023/05/23/podman-desktop-now-generally-available"&gt;Podman Desktop 1.0: Local container development made easy &lt;/a&gt;&lt;/li&gt; &lt;li&gt;Documentation: &lt;a href="https://docs.openshift.com/container-platform/4.13/applications/odc-viewing-application-composition-using-topology-view.html"&gt;Viewing application composition using the Topology view &lt;/a&gt;&lt;/li&gt; &lt;li&gt;Documentation: &lt;a href="https://www.redhat.com/en/topics/application-modernization"&gt;Modernizing existing applications&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Ready to try?&lt;/h3&gt; &lt;p&gt;Start analyzing and assessing applications with MTA. Learn from our demo and product documentation.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=u9N-T-uD_KU"&gt;Migration Toolkit For Applications&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Learn more about migration&lt;/h3&gt; &lt;p&gt;Plan your Java application modernization journey with our e-book and learn Podman's capabilities.&lt;/p&gt; &lt;ul&gt;&lt;li class="Indent1"&gt;Article: &lt;a href="https://developers.redhat.com/articles/2022/05/02/podman-basics-resources-beginners-and-experts#"&gt;Podman basics &lt;/a&gt;&lt;/li&gt; &lt;li class="Indent1"&gt;E-book: &lt;a href="https://www.redhat.com/en/engage/java-application-modernization-20220926"&gt;A practical guide to kick-start your own initiative&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;4. Automate to accelerate your software development lifecycle&lt;/h2&gt; &lt;p&gt;Automate software development process adopting GitOps approach and secure with DevSecOps.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Article: &lt;a href="https://developers.redhat.com/articles/2022/09/07/how-set-your-gitops-directory-structure"&gt;How to set up your GitOps directory structure&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Article: &lt;a href="https://developers.redhat.com/articles/2022/07/20/git-workflows-best-practices-gitops-deployments"&gt;Git best practices: Workflows for GitOps deployments&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Documentation: &lt;a href="https://www.redhat.com/en/topics/devops/what-is-devsecops"&gt;What's DevSecOps &lt;/a&gt;&lt;/li&gt; &lt;li&gt;Documentation and demos: &lt;a href="https://developers.redhat.com/topics/devsecops"&gt;DevSecOps: Automating security in the development lifecycle&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Ready to try automation?&lt;/h3&gt; &lt;p&gt;Learn from these free hands-on labs how to bring automation with CI/CD and GitOps practices by using Helm, OpenShift Pipelines, Jenkins, Ansible Automation Platform, and OpenShift GitOps.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/learn/openshift/develop-gitops"&gt;Develop with GitOps &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/courses/gitops/getting-started-openshift-pipelines"&gt;Getting Started with OpenShift Pipelines&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/courses/cicd-ansible-automation-platform-and-jenkins-openshift"&gt;CI/CD with the Ansible Automation Platform and Jenkins on OpenShift &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/courses/gitops/working-helm"&gt;Working with Helm&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Learn more about DevOps&lt;/h3&gt; &lt;p&gt;These e-books will help you start with best practices and practical guides to transform into a DevOps culture.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/e-books/path-gitops"&gt;The Path to GitOps &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.redhat.com/en/engage/devops-culture-practice-openshift-ebooks"&gt;DevOps Culture and Practice with OpenShift&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Our product documentation&lt;/h3&gt; &lt;p&gt;Review our product documentation to learn about features and much more.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.13/cicd/index.html"&gt;OpenShift CI/CD &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.13/applications/working_with_helm_charts/understanding-helm.html"&gt;Understanding Helm &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.13/cicd/gitops/understanding-openshift-gitops.html"&gt;Understanding OpenShift GitOps&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;5. How to innovate with OpenShift&lt;/h2&gt; &lt;p&gt;Learn about key OpenShift capabilities to bring innovation to applications from serverless architectures, interconnecting services in diverse platforms, and securing and observing microservices with OpenShift Service Mesh.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Documentation: &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/serverless"&gt;What's Red Hat OpenShift &lt;/a&gt;&lt;/li&gt; &lt;li&gt;Documentation: &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/serverless"&gt;Serverless&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Documentation: &lt;a href="https://developers.redhat.com/products/service-interconnect/overview"&gt;Interconnect applications and microservices across the open hybrid cloud&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Tutorials, books, videos and more: &lt;a href="https://developers.redhat.com/topics/serverless-architecture#assembly-field-sections-38375"&gt;Build serverless architectures for Kubernetes with Knative &lt;/a&gt;&lt;/li&gt; &lt;li&gt;Documentation: &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/what-is-openshift-service-mesh"&gt;What's Red Hat OpenShift Service Mesh&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Ready to try OpenShift components?&lt;/h3&gt; &lt;p&gt;Gather hands-on experience with our free labs and follow tutorials and demos at your own pace.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Hands-on lab: &lt;a href="https://developers.redhat.com/courses/getting-started-openshift-serverless"&gt;Getting Started with OpenShift Serverless &lt;/a&gt;&lt;/li&gt; &lt;li&gt;Demo: &lt;a href="https://www.youtube.com/watch?v=YoGR5zZGG9k"&gt;OpenShift Service Mesh&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Learn more about OpenShift Service Mesh&lt;/h3&gt; &lt;p&gt;This e-book provides guidance on governance, design practices, and configuring Red Hat OpenShift Service Mesh for production use and performing day-2 operations. &lt;/p&gt; &lt;ul&gt;&lt;li&gt;E-book: &lt;a href="https://www.redhat.com/en/resources/getting-started-with-openshift-service-mesh-ebook"&gt;Getting Started with Red Hat OpenShift Service Mesh&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Find more resources in our product documentation&lt;/h3&gt; &lt;p&gt;Learn about product capabilities, features, and much more from our product documentation.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.13/service_mesh/v2x/ossm-about.html"&gt;OpenShift Service Mesh &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.13/serverless/about/about-serverless.html"&gt;OpenShift Serverless &lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://docs.openshift.com/container-platform/4.13/distr_tracing/distributed-tracing-release-notes.html"&gt;Distributed Tracing&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/07/13/developers-path-success-openshift-and-containers" title="A developer’s path to success with OpenShift and containers"&gt;A developer’s path to success with OpenShift and containers&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Valentina Rodriguez Sosa</dc:creator><dc:date>2023-07-13T07:00:00Z</dc:date></entry><entry><title type="html">Quarkus Newsletter #34 - July</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-newsletter-34/" /><author><name>James Cobb</name></author><id>https://quarkus.io/blog/quarkus-newsletter-34/</id><updated>2023-07-13T00:00:00Z</updated><content type="html">Read "Quarkus 3.2.0.Final released - New security features, @QuarkusComponentTest" by Guillaume Smet" to learn about major changes like; various new security features, the ability to test CDI components with @QuarkusComponentTest and new build time analytics. Kevin Dubois' article "Managing Java containers with Quarkus and Podman Desktop" shows how to build...</content><dc:creator>James Cobb</dc:creator></entry><entry><title>How to create an instance on GCP using the Ansible CLI</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/07/12/how-create-instance-gcp-using-ansible-cli" /><author><name>Deepankar Jain</name></author><id>db5556aa-b189-409a-9e92-a77ccdafba55</id><updated>2023-07-12T07:00:00Z</updated><published>2023-07-12T07:00:00Z</published><summary type="html">&lt;p&gt;This series covers the end-to-end process of creating an instance on Google Cloud Platform (GCP) using Red Hat Ansible Automation Platform. This 3-part series includes:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Part 1: How to create an instance on GCP using Ansible CLI&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Part 2: &lt;a href="https://developers.redhat.com/articles/2023/07/12/how-create-gcp-instance-using-ansible-automation"&gt;How to create a GCP instance using Ansible Automation&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Part 3: &lt;a href="https://developers.redhat.com/articles/2023/07/12/how-create-gcp-instance-workflow-and-ansible"&gt;How to create a GCP instance via workflow and Ansible&lt;/a&gt;&lt;/p&gt; &lt;p&gt;By the end of this article, you will have a clear understanding of how to use the Ansible Automation Platform CLI to automate the creation of GCP instances, which will save you time and reduce the risk of manual errors. Let's get started!&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;&lt;a href="https://developers.redhat.com/products/ansible/getting-started"&gt;Ansible&lt;/a&gt; installed on your system.&lt;/li&gt; &lt;li aria-level="1"&gt;An active GCP Account with sufficient permissions.&lt;/li&gt; &lt;li aria-level="1"&gt;Ansible &lt;a href="https://galaxy.ansible.com/google/cloud"&gt;google cloud collection&lt;/a&gt; installed on your system.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;We will start by setting up the necessary credentials and roles for our Ansible playbook to access the GCP API. Then we will create a disk, a network, a security group, and an IP address before finally launching the instance.&lt;/p&gt; &lt;h2&gt;How to use Ansible CLI&lt;/h2&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Create a &lt;a href="https://support.google.com/a/answer/7378726?hl=en"&gt;service account&lt;/a&gt; in GCP.&lt;/li&gt; &lt;li aria-level="1"&gt;Generate the &lt;a href="https://developers.google.com/workspace/guides/create-credentials#create_credentials_for_a_service_account"&gt;credentials&lt;/a&gt; for the service account.&lt;/li&gt; &lt;li aria-level="1"&gt;You should now have a credential.json&lt;strong&gt; &lt;/strong&gt;file&lt;strong&gt; &lt;/strong&gt;that you can use to access your GCP account and launch an instance.&lt;/li&gt; &lt;li aria-level="1"&gt;Open any editor and copy the following yml into it.&lt;/li&gt; &lt;/ul&gt;&lt;pre&gt; &lt;code class="language-yaml"&gt;--- - name: Create instance in GCP   hosts: localhost   gather_facts: false   vars:     service_account_file: "&lt;path to service account file&gt;"     project: "&lt;SOMETHING&gt;"     network_name: "test-ansible-network"     subnet_name: "test-ansible-subnet"     ip_name: "test-ansible-ip"     disk_name: "test-ansible-disk"     machine_name: "test-ansible"     region: "asia-south2"     zone: "asia-south2-a"     source_image: "projects/ubuntu-os-cloud/global/images/family/ubuntu-1804-lts"     subnet_cidr: "10.0.1.0/24"     disk_size: 10     machine_type: "f1-micro"   tasks:     - name: Create a disk       google.cloud.gcp_compute_disk:         name: "{{ disk_name }}"         size_gb: "{{ disk_size }}"         source_image: "{{ source_image }}"         zone: "{{ zone }}"         project: "{{ project }}"         auth_kind: serviceaccount         service_account_file: "{{ service_account_file }}"         state: present       register: disk          - name: Create a Network in GCP       google.cloud.gcp_compute_network:         auth_kind: serviceaccount         project: "{{ project }}"         service_account_file: "{{ service_account_file }}"         name: "{{ network_name }}"         auto_create_subnetworks: false         state: present       register: network     - name: Create a Subnet in the Network       google.cloud.gcp_compute_subnetwork:         auth_kind: serviceaccount         project: "{{ project }}"         service_account_file: "{{ service_account_file }}"         name: "{{ subnet_name }}"         region: "{{ region }}"         ip_cidr_range: "{{ subnet_cidr }}"         network: "{{ network }}"         state: present       register: subnet     - name: Reserve a static IP Address       google.cloud.gcp_compute_address:         auth_kind: serviceaccount         project: "{{ project }}"         service_account_file: "{{ service_account_file }}"         name: "{{ ip_name }}"         region: "{{ region }}"         state: present       register: address              - name: Create an Instance        google.cloud.gcp_compute_instance:         auth_kind: serviceaccount         project: "{{ project }}"         service_account_file: "{{ service_account_file }}"         state: present         name: "{{ machine_name }}"         machine_type: "{{ machine_type }}"         zone: "{{ zone }}"         disks:           - auto_delete: true             boot: true             source: "{{ disk }}"         network_interfaces:           - network: "{{ network }}"             subnetwork: "{{ subnet }}"             access_configs:               - name: External NAT                 type: ONE_TO_ONE_NAT                 nat_ip: "{{ address }}" &lt;/code&gt;&lt;/pre&gt; &lt;ul&gt;&lt;li&gt;Save and close the file.&lt;/li&gt; &lt;li&gt;Then open the terminal in the directory where the file is located.&lt;/li&gt; &lt;li aria-level="1"&gt;Now run the following command: &lt;pre&gt; &lt;code class="language-bash"&gt;ansible-playbook &lt;filename&gt;.yml&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;/ul&gt;&lt;p&gt;The output:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;PLAY [Create instance in GCP] ************************************************************************************************************************************************************ TASK [Gathering Facts] ******************************************************************************************************************************************************************************************** ok: [localhost] TASK [Create a disk] ************************************************************************************************************************************************************************************ changed: [localhost] TASK [Create a Network in GCP] *********************************************************************************************************************************************************************************** changed: [localhost] TASK [Create a Subnet in the Network] ******************************************************************************************************************************************************************************************** changed: [localhost] TASK [Reserve a static IP Address] ********************************************************************************************************************************************************************************* changed: [localhost] TASK [Create an Instance] ******************************************************************************************************************************************* changed: [localhost] PLAY RECAP ******************************************************************************************************************************************************************************************************** localhost : ok=6 changed=5 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The GCP instance is shown in Figure 1.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_from_2023-04-27_10-54-25.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_from_2023-04-27_10-54-25.png?itok=g2s4Y660" width="600" height="169" alt="Creating a GCP instance." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: Creating a GCP instance.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;By following the step-by-step guide, you should now have a good understanding of how to use Ansible to automate the creation of a virtual machine. To learn more about Ansible and access additional resources and guides, including diverse examples and use cases, we recommend visiting &lt;a href="https://developers.redhat.com/learn/ansible"&gt;Red Hat Ansible Automation Platform&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;What’s next?&lt;/h2&gt; &lt;p&gt;In our &lt;a href="https://developers.redhat.com/articles/2023/07/12/how-create-gcp-instance-using-ansible-automation"&gt;next article&lt;/a&gt;, we will explore how &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Ansible Automation Platform&lt;/a&gt; further eases the process of creating virtual machines by enabling you to define infrastructure as code, track infrastructure changes, and enforce compliance policies. If you're interested in exploring how to use &lt;a href="https://developers.redhat.com/learn/ansible"&gt;Ansible Automation Platform&lt;/a&gt; on Azure, you can also access the &lt;a href="https://developers.redhat.com/content-gateway/link/3872066"&gt;lab&lt;/a&gt;. This lab allows you to try Ansible Automation Platform on Azure and learn how it can be used to automate infrastructure deployment.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/ansible/getting-started"&gt;Get started&lt;/a&gt; with Ansible Automation Platform by exploring interactive hands-on labs. &lt;a href="https://developers.redhat.com/products/ansible/download"&gt;Download Ansible Automation Platform&lt;/a&gt; at no cost and begin your automation journey. You can refer to &lt;a href="https://developers.redhat.com/e-books/choosing-automation-tool"&gt;An IT executive's guide to automation&lt;/a&gt; e-book for a better understanding of the Ansible Automation Platform.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/07/12/how-create-instance-gcp-using-ansible-cli" title="How to create an instance on GCP using the Ansible CLI"&gt;How to create an instance on GCP using the Ansible CLI&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Deepankar Jain</dc:creator><dc:date>2023-07-12T07:00:00Z</dc:date></entry><entry><title type="html">On the Road to CDI Compatibility</title><link rel="alternate" href="https://quarkus.io/blog/on-the-road-to-cdi-compatibility/" /><author><name>Ladislav Thon</name></author><id>https://quarkus.io/blog/on-the-road-to-cdi-compatibility/</id><updated>2023-07-12T00:00:00Z</updated><content type="html">Ever since the very first days of Quarkus, the days that are now covered by the blissful fog of oblivion and the survivors only talk about them after a few pints of beer, dependency injection container was an integral part of the envisioned framework. And not just any dependency injection...</content><dc:creator>Ladislav Thon</dc:creator></entry><entry><title type="html">Groupby &amp;#8211; a new way to accumulate facts in DRL</title><link rel="alternate" href="https://blog.kie.org/2023/07/groupby-a-new-way-to-accumulate-facts-in-drl.html" /><author><name>Christopher Chianelli</name></author><id>https://blog.kie.org/2023/07/groupby-a-new-way-to-accumulate-facts-in-drl.html</id><updated>2023-07-11T09:00:00Z</updated><content type="html">Have you ever wanted to accumulate facts that share a particular property (for instance, the count of people in each department) in DRL? With the addition of groupby to DRL, it is easier to write rules that divide facts into groups where each group is accumulated separately. In this post, we’ll explain what groupby is, how to use it, and give examples of groupby usage. WHAT IS GROUPBY? Groupby is a new syntax construct introduced in 8.41.0.Final for dividing facts into groups, allowing each group to be accumulated separately. It has the following syntax: groupby(source-pattern; grouping-key; accumulators [; constraints]) Where: * source-pattern: Pattern used to gather facts that will be grouped and accumulated. For instance, using $a: /applicants[age &lt; 21] as the source-pattern would group and accumulate all Applicants under the age of 21 (binding the applicant to $a, which can be used in the grouping-key and accumulators). The examples in this article use the OOPath syntax for source-pattern, but the traditional syntax is also supported. For more details, see . * grouping-key: A function used to divide the source-pattern into separate groups. Facts from source-pattern for which grouping-key returns the same value are grouped together. The key can optionally be bound to a variable, allowing it to be used outside the groupby. For example, using $country: $a.country as the grouping key would group applicants by country, binding the country for the group to the $country variable. * accumulators: One or more accumulate functions used to accumulate the facts in each group. Each accumulate function can optionally be bound to a variable, allowing it to be used outside the groupby. For instance, $count: count() would count the number of applicants younger than 21 from each country. * constraints: Optional constraints on the group key and accumulation result. The rest of the rule will only execute for the given group key if all constraints return true. For instance, $count &gt;= 100 would only continue execution of the rule for a given $country if that country have at least 100 applicants younger than 21. Combining the above example together, we get: groupby( $a: /applicants[age &lt; 21]; $country: $a.country; $count: count(); $count &gt;= 100 ) HOW TO USE GROUPBY You can use groupby by upgrading Drools to 8.41.0.Final or later. Groupby can then be used in your DRL files like any other language construct (such as forall and accumulate). EXAMPLE GROUPBY USAGE Groupby is a good choice whenever you need to accumulate results for separate groups. Some examples of rules that can be implemented with it include: * Get departments over budget rule "Departments over budget" groupby($order: /order; $department: $order.department; $totalCost: sum($order.cost); $totalCost &gt; $department.budget ) then // ... end * Find days which are understaffed rule "Understaffed Days" groupby($shift: /shifts[ employee != null ]; $date: $shift.date; $assignedCount: count(); $assignedCount &lt; $date.minimumAssignedShifts ) then // ... end * Get the highest bid for a product rule "Highest bid for a product" groupby($bid: /bids; $product: $bid.product; $highestBid: max($bid) ) then // ... end CONCLUSION Groupby is a new language feature introduced in 8.41.0.Final that allows for simpler grouping of objects by a key function. You can use it by upgrading Drools to 8.41.0.Final or later. Groupby is useful for implementing rules that accumulate facts that share a given property, such as getting the total cost by department or getting the highest bidder by product. The post appeared first on .</content><dc:creator>Christopher Chianelli</dc:creator></entry><entry><title>How to deploy a MSSQL database using Ansible Vault</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/07/11/how-deploy-mssql-database-using-ansible-vault" /><author><name>Deepankar Jain</name></author><id>3d92a4ae-f9d6-4a0d-8f2b-0f9fe1975694</id><updated>2023-07-11T07:00:00Z</updated><published>2023-07-11T07:00:00Z</published><summary type="html">&lt;p&gt;Deploying and configuring a database can be a challenging task, especially when sensitive data such as passwords and API keys are involved. However, by using &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Red Hat Ansible Automation Platform&lt;/a&gt; and &lt;a href="https://docs.ansible.com/ansible/2.8/user_guide/vault.html#:~:text=Ansible%20Vault%20is%20a%20feature,or%20placed%20in%20source%20control."&gt;Ansible Vault&lt;/a&gt;, we can streamline the process and ensure that our data is secure. In this article, we will explore how to configure and deploy a Microsoft SQL database using Ansible Vault, an Ansible Automation Platform feature.&lt;/p&gt; &lt;p&gt;We will walk you through the process, step-by-step, so that you can easily follow along and try it for yourself. By the end of this article, you will have a solid understanding of how to use Ansible Vault to deploy a secure database, making your deployment process more efficient and secure.&lt;/p&gt; &lt;p&gt;Before you begin, make sure to &lt;a href="https://developers.redhat.com/products/ansible/download"&gt;download&lt;/a&gt; and install Ansible Automation Platform, available at no cost. For more information about Ansible Automation Platform installation, please refer to our previous article, &lt;a href="https://developers.redhat.com/articles/2023/01/01/how-install-red-hat-ansible-automation-platform-rhel-9#"&gt;How to install Red Hat Ansible Automation Platform on RHEL 9&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Enhancing database security with Ansible Automation Platform&lt;/h2&gt; &lt;p&gt;&lt;a href="https://docs.ansible.com/ansible/2.8/user_guide/vault.html#:~:text=Ansible%20Vault%20is%20a%20feature,or%20placed%20in%20source%20control."&gt;Ansible Vault&lt;/a&gt; is a powerful tool for keeping sensitive information, such as passwords, hidden from prying eyes. You can easily encrypt sensitive data and keep it separate from your code. This provides an added layer of security and ensures that only authorized personnel can access sensitive information. With this, you can manage passwords and other sensitive data in a secure manner, without having to modify the code itself. In this demonstration, we'll be working with a &lt;a href="https://github.com/redhat-developer-demos/MicrosoftSQL-AAP-on-RHEL"&gt;repository&lt;/a&gt; that demonstrates how to use Ansible Automation Platform to deploy and manage MSSQL databases. To protect the MSSQL password in our playbook, we made some modifications that improved our security and simplified our playbook management.&lt;/p&gt; &lt;p&gt;First, we removed the mssql_password key from our playbook, as this was a potential security vulnerability.&lt;/p&gt; &lt;p&gt;The original playbook:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;vars: mssql_password: "123@Redhat" mssql_edition: Evaluation ... &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The modified playbook:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;vars: mssql_edition: Evaluation ... &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then, we created a new YAML file called mssql_password.yml to store the password separately from the playbook code. By doing this, we were able to keep the password secure and prevent it from being exposed in our code.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;mssql_password.yml&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;vars: mssql_password: "123@Redhat" &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then encrypt the mssql_password.yml using ansible vault:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;ansible-vault encrypt mssql_password.yml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We will be prompted to enter a password to encrypt the file. Modify the playbook to include mssq_password as a vars file.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;--- - hosts: dev vars_files: sql_password.yml vars: …… &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We’re now ready to run this playbook on Ansible Automation Platform.&lt;/p&gt; &lt;h3&gt;Step 1: Set up the automation execution environment&lt;/h3&gt; &lt;p&gt;Automation execution environments provide a defined, consistent, and portable environment for executing automation jobs. Unlike legacy virtual environments, automation execution environments are Linux container images that make it possible to incorporate system-level dependencies and collection-based content. Each automation execution environment allows you to have a customized image to run jobs, and each of them contains only what you need when running the job.&lt;/p&gt; &lt;p&gt;There are dependencies for the automation execution environment, such as Python 3 and Podman. Make sure these tools are installed. We have provided instructions for installing and using Podman in this &lt;a href="https://developers.redhat.com/videos/youtube/bJDI_QuXeCE"&gt;video&lt;/a&gt;. Before you can complete any of the following tasks, you must create a registry &lt;a href="https://access.redhat.com/terms-based-registry/"&gt;service account&lt;/a&gt;. To log in to SA, you'll need to use a container runtime such as Podman or Docker. &lt;a href="https://developers.redhat.com/videos/youtube/bJDI_QuXeCE"&gt;Podman&lt;/a&gt; is a powerful and secure open source tool that can be used as an alternative to Docker, with the added benefits of not requiring a daemon to run containers and having a more lightweight footprint. If you don't have Podman &lt;a href="https://podman.io/getting-started/installation"&gt;installed&lt;/a&gt;, you can use Docker instead, but we recommend using Podman for a more efficient &lt;a href="https://developers.redhat.com/articles/podman-next-generation-linux-container-tools"&gt;container experience&lt;/a&gt;. To log in, open up your terminal and type the following commands:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;podman login registry.redhat.io Username: {REGISTRY-SERVICE-ACCOUNT-USERNAME} Password: {REGISTRY-SERVICE-ACCOUNT-PASSWORD}   Login Succeeded!&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once we are successfully logged in, we need to create a container image by using a container file containing the following context:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;FROM registry.redhat.io/ansible-automation-platform-22/ee-29-rhel8:latest RUN ansible-galaxy collection install microsoft.sql&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To build an image using &lt;code&gt;podman&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;podman build -t &lt;image-name&gt;.&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The image should be pushed into the container image registry. Log in to the private container image registry using the command &lt;code&gt;podman login&lt;/code&gt; before pushing.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;podman push &lt;image-name&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Add the image name in the automation execution environment, as shown in Figure 1.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_2023-04-13_003136.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_2023-04-13_003136.png?itok=mATj6vlV" width="600" height="292" alt="A screenshot of the execution environment page." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The execution environment page.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Step 2: Set up the inventory&lt;/h3&gt; &lt;p&gt;An inventory is a collection of hosts against which jobs may be launched. To create inventory in Ansible Automation Platform, follow these steps and refer to Figure 2:&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Select the inventory from the left menu.&lt;/li&gt; &lt;li aria-level="1"&gt;Click on &lt;strong&gt;add&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Select &lt;strong&gt;add inventory&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Give a name to the inventory and save it.&lt;/li&gt; &lt;li aria-level="1"&gt;Select the groups from inventories and click &lt;strong&gt;add group&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Give a name to the group and save it.&lt;/li&gt; &lt;li aria-level="1"&gt;Next, click on Hosts and click &lt;strong&gt;add a new host&lt;/strong&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;Give the targeted server IP and save it.&lt;/li&gt; &lt;/ol&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig-2-mssql.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig-2-mssql.png?itok=Tk-AnMXs" width="600" height="176" alt="A screenshot of the inventory page in Ansible." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: Creating inventory on the Inventory page.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Step 3: Set up the credentials&lt;/h3&gt; &lt;p&gt;To connect with the target server and decrypting the mssql_password.yml, we need credentials such as username, password, or ssh key of the target machine and password of the ansible vault. By using credentials, we can pass the required credentials during the playbook execution.&lt;/p&gt; &lt;p&gt;Follow these steps and refer to Figure 3 to set up the ssh machine credentials.&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Select the credentials from the left menu.&lt;/li&gt; &lt;li aria-level="1"&gt;Click on new credentials and select Machine credentials type.&lt;/li&gt; &lt;li aria-level="1"&gt;Add your username, password, or ssh key in the corresponding fields.&lt;/li&gt; &lt;li aria-level="1"&gt;(Optional) You'll be needed to run privileged commands on the remote machine, enter the sudo password in the Privilege Escalation section. This will allow Ansible controller to escalate privileges when necessary&lt;/li&gt; &lt;/ol&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig-3-mssql-blog.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig-3-mssql-blog.png?itok=t-2j_aDL" width="600" height="219" alt="A screenshot of the machine credential page." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: The machine credentials page.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Set up the Ansible Vault credentials (Figure 4):&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Click on new credentials and select vault type.&lt;/li&gt; &lt;li aria-level="1"&gt;Add a name to the credential and the vault password as the password you used for encrypting your mssql_password.yml (in our case, 12345678).&lt;/li&gt; &lt;/ol&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig-4-mssql.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig-4-mssql.png?itok=ONS0DWCO" width="600" height="190" alt="A screenshot of the vault credentials page." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 4: The vault credentials page.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Step 4: Configure a project&lt;/h3&gt; &lt;p&gt;A project is a logical collection of Ansible Playbooks represented in the controller. You can manage playbooks and playbook directories on your controller server either manually or by using a source code management (SCM) system, such as Git, Subversion, or Mercurial supported by the controller.&lt;/p&gt; &lt;p&gt;Follow these steps to create a project and refer to Figure 5:&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Create a new project for our git repository from the left menu.&lt;/li&gt; &lt;li aria-level="1"&gt;Click on the + icon in the right corner.&lt;/li&gt; &lt;li aria-level="1"&gt;Give the project a name.&lt;/li&gt; &lt;li aria-level="1"&gt;Select your organization (or choose &lt;strong&gt;Default&lt;/strong&gt;).&lt;/li&gt; &lt;li aria-level="1"&gt;Select the SCM TYPE (GIT in our case).&lt;/li&gt; &lt;li aria-level="1"&gt;Add RESOURCE DETAILS&lt;/li&gt; &lt;li aria-level="1"&gt;SCM &lt;a href="https://github.com/decipher07/Integrate-Ansible-Vault-Controller"&gt;URL&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;SCM BRANCH(main)&lt;/li&gt; &lt;li aria-level="1"&gt;SCM CREDENTIAL&lt;/li&gt; &lt;li aria-level="1"&gt;Save it.&lt;/li&gt; &lt;/ol&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_2023-04-13_003744.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_2023-04-13_003744.png?itok=XyfCsqWY" width="600" height="278" alt="Figure 4: The Templates page." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 5: The Templates page.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Step 5: Configure the templates&lt;/h3&gt; &lt;p&gt;&lt;a href="https://docs.ansible.com/automation-controller/latest/html/userguide/glossary.html#term-Job-Template"&gt;Templates&lt;/a&gt; define and set parameters for running jobs. A template is more like a blueprint where all of the dependencies are defined, such as inventory, projects, credentials, etc.&lt;/p&gt; &lt;p&gt;Follow these steps to create a template to execute the job for us (Figure 5):&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;From the left menu, select templates and create a new template.&lt;/li&gt; &lt;li aria-level="1"&gt;Click on the &lt;strong&gt;+&lt;/strong&gt; icon from the right corner and select the Job template.&lt;/li&gt; &lt;li aria-level="1"&gt;Give the template a name.&lt;/li&gt; &lt;li aria-level="1"&gt;Select the project and playbook you want to run in the template.&lt;/li&gt; &lt;li aria-level="1"&gt;Select &lt;a href="https://github.com/redhat-developer-demos/MicrosoftSQL-AAP-on-RHEL/blob/main/MicrosoftSQL-with-ansible-vault/microsoft_sql_playbook.yml"&gt;MicrosoftSQL-with-ansible-vault/microsoft_sql_playbook.yml&lt;/a&gt; playbook.&lt;/li&gt; &lt;li aria-level="1"&gt;Select the execution environment which you created previously and make sure to check the &lt;strong&gt;Privilege Escalation &lt;/strong&gt;option if you have that enabled with your ssh credentials.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;If you haven't set up the privilege escalation password during the SSH credential, you can use still run the playbook by setting a variable called &lt;strong&gt;ansible_sudo_pass&lt;/strong&gt; with the value as the password to your VM.&lt;/p&gt; &lt;ol start="7"&gt;&lt;li aria-level="1"&gt;Launch It (Figure 6).&lt;/li&gt; &lt;/ol&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig-5-mssql-blog.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/fig-5-mssql-blog.png?itok=WgY97UEO" width="600" height="282" alt="A successful installation of Microsoft SQL server." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 6: A successful installation of Microsoft SQL server after launching.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;Using Ansible Automation Platform and Ansible Vault can greatly enhance the security of your database deployments by keeping sensitive information like passwords separate from the code and protecting it from unauthorized access. To explore more of what Ansible Automation Platform has to offer, visit the &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;official website&lt;/a&gt; to &lt;a href="https://developers.redhat.com/products/ansible/download"&gt;download&lt;/a&gt; and &lt;a href="https://developers.redhat.com/products/ansible/getting-started"&gt;get started&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Additionally, these e-books can help you explore the capabilities of Ansible Automation Platform:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/e-books/automation-at-the-edge"&gt;Automation at the Edge&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/e-books/choosing-automation-tool"&gt;Choosing an Automation Tool&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/e-books/it-executives-guide-automation"&gt;An IT Executive's Guide to Automation&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;A cheat sheet is also available for &lt;a href="https://developers.redhat.com/cheat-sheets/wifi-automation-ansible-and-sd-wan-meraki-cheat-sheet"&gt;WiFi automation with Ansible and SD&lt;/a&gt;, providing a quick reference for network automation tasks.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/07/11/how-deploy-mssql-database-using-ansible-vault" title="How to deploy a MSSQL database using Ansible Vault"&gt;How to deploy a MSSQL database using Ansible Vault&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Deepankar Jain</dc:creator><dc:date>2023-07-11T07:00:00Z</dc:date></entry><entry><title type="html">Keycloak 22.0.0 released</title><link rel="alternate" href="https://www.keycloak.org/2023/07/keycloak-2200-released" /><author><name /></author><id>https://www.keycloak.org/2023/07/keycloak-2200-released</id><updated>2023-07-11T00:00:00Z</updated><content type="html">To download the release go to . RELEASE NOTES SERVER DISTRIBUTION JAVA 11 SUPPORT REMOVED Running the Keycloak server with Java 11 is no longer supported. Java 11 was deprecated in Keycloak 21 with the announced plan to be removed in Keycloak 22. UPGRADE TO QUARKUS 3.X Keycloak upgraded to version 3.2.0.Final of the Quarkus Java framework. Quarkus 3.x continues the tradition of propelling Java development by moving fast and providing a cutting-edge user experience with the latest technologies. TRANSITION FROM JAVA EE TO JAKARTA EE As part of upgrading to Quarkus 3.x Keycloak migrated its codebase from Java EE (Enterprise Edition) to its successor Jakarta EE, which brings various changes into Keycloak. We have upgraded all Jakarta EE specifications in order to support Jakarta EE 10. CONTEXT AND DEPENDENCY INJECTION NO LONGER ENABLED TO JAX-RS RESOURCES In order to provide a better runtime and leverage as much as possible the underlying stack, all injection points for contextual data using the javax.ws.rs.core.Context annotation were removed. The expected improvement in performance involves no longer creating proxies instances multiple times during the request lifecycle, and drastically reducing the amount of reflection code at runtime. UPGRADE TO HIBERNATE ORM 6 Keycloak now benefits from the upgrade to Hibernate ORM 6.2, which includes improved performance, better SQL, modern JDK support, and support for modern RDBMS features. ELYTRON CREDENTIAL STORE REPLACEMENT The previous and now removed WildFly distribution provided a built-in vault provider that reads secrets from a keystore-backed Elytron credential store. As this is no longer available, we have added a new implementation of the Keycloak Vault SPI called Keycloak KeyStore Vault. As the name suggests, this implementation reads secrets from a Java keystore file. Such secrets can be then used within multiple places of the Administration Console. For further details, see and the latest . KEYSTORE CONFIG SOURCE ADDED In relation to the KeyStore Vault news, we also integrated Quarkus’s recently released feature called KeyStore Config Source. This means that among the already existing configuration sources (CLI parameters, environment variables and files), you can now configure your Keycloak server via configuration properties stored in a Java keystore file. You can learn more about this feature in the . HOSTNAME DEBUG TOOL As a number of users have had problems with configuring the hostname for the server correctly there is now a new helper tool to allow debugging the configuration. PASSTHROUGH PROXY MODE CHANGES Installations which use Keycloak’s --proxy configuration setting with mode passthrough should review the documentation as the behavior of this mode has changed. EXPORT AND IMPORT PERFORM AN AUTOMATIC BUILD In previous releases, the export and import commands required a build command to be run first. Starting with this release, the export and import commands perform an automatic rebuild of Keycloak if a build time configuration has changed. ADMIN CONSOLE ACCOUNT CONSOLE V1 REMOVAL The old Account Console (v1) is now completely removed. This version of the Account Console was marked as deprecated in Keycloak 12. ACCOUNT CONSOLE V3 PROMOTED TO PREVIEW In version 21.1.0 of Keycloak the new Account Console (version 3) was introduced as an experimental feature. Starting this version it has been promoted to a preview feature. ACCOUNT CONSOLE TEMPLATE VARIABLES REMOVED Two of the variables exposed to the Account Console V2 and V3 templates (isEventsEnabled and isTotpConfigured) were left unused, and have been removed in this release. It is possible that if a developer extended the Account Console theme, he or she could make use of these variables. So make sure that these variables are no longer used if you are extending the base theme. CHANGES TO CUSTOM ADMIN CONSOLE MESSAGES The Admin Console (and soon also the new Account Console) works slightly different than the rest of Keycloak in regards to how keys for internationalized messages are parsed. This is due to the fact that it uses the library for internationalization. Therefore when defining custom messages for the Admin Console under "Realm Settings" ➡ "Localization" best practices for i18next must be taken into account. Specifically, when defining a message for the Admin Console it is it important to specify a in the key of your message. For example, let’s assume we want to overwrite the message shown to the user when a new realm has been created. This message is located in the dashboard namespace, same as the name of the original file that holds the messages (dashboard.json). If we wanted to overwrite this message we’ll have to use the namespace as a prefix followed by the key of the message separated by a colon, in this case it would become dashboard:welcome. JAVASCRIPT ADAPTER LEGACY PROMISE API REMOVED With this release, we have removed the legacy Promise API methods from the Keycloak JS adapter. This means that calling .success() and .error() on promises returned from the adapter is no longer possible. REQUIRED TO BE INSTANTIATED WITH THE NEW OPERATOR In a previous release we started to actively log deprecation warnings when the Keycloak JS adapter is constructed without the new operator. Starting this release doing so will throw an exception instead. This is to align with the expected behavior of , which will allow further refactoring of the adapter in the future. ADMIN API RENAMED ADMIN LIBRARY ARTIFACTS After the upgrade to Jakarta EE, artifacts for Keycloak Admin clients were renamed to more descriptive names with consideration for long-term maintainability. We still provide two separate Keycloak Admin clients, one with Jakarta EE and the other with Java EE support. SUPPORT FOR COUNT USERS BASED ON CUSTOM ATTRIBUTES The User API now supports querying the number of users based on custom attributes. For that, a new q parameter was added to the /{realm}/users/count endpoint. The q parameter expects the following format q=&lt;name&gt;:&lt;value&gt; &lt;name&gt;:&lt;value&gt;. Where &lt;name&gt; and &lt;value&gt; represent the attribute name and value, respectively. OPERATOR K8S.KEYCLOAK.ORG/V2ALPHA1 CHANGES The are additional fields available in the keycloak.status to facilitate keycloak being a scalable resource. There are also additional fields that make the status easier to interpret such as observedGeneration and condition observedGeneration and lastTransitionTime fields. The condition status field was changed from a boolean to a string for conformance with standard Kubernetes conditions. In the CRD it will temporarily be represented as accepting any content, but it will only ever be a string. Please make sure any of your usage of this field is updated to expect the values "True", "False", or "Unknown", rather than true or false. CO-MANAGEMENT OF OPERATOR RESOURCES In scenarios where advanced management is needed you may now directly update most fields on operator managed resources that have not been set by the operator directly. This can be used as an alternative to the unsupported stanza of the Keycloak spec. Like the unsupported stanza these direct modifications are not considered supported. If your modifications prevent the operator from being able to manage the resource, there Keycloak CR will show this error condition and the operator will log it. IDENTITY BROKERING ESSENTIAL CLAIM CONFIGURATION IN OPENID CONNECT IDENTITY PROVIDERS OpenID Connect identity providers support a new configuration to specify that the ID tokens issued by the identity provider must have a specific claim, otherwise the user can not authenticate through this broker. The option is disabled by default; when it is enabled, you can specify the name of the JWT token claim to filter and the value to match (supports regular expression format). SUPPORT FOR JWE ENCRYPTED ID TOKENS AND USERINFO RESPONSES IN OPENID CONNECT PROVIDERS The OpenID Connect providers now support for the ID Token and the UserInfo response. The providers use the realm keys defined for the selected encryption algorithm to perform the decryption. HARDCODED GROUP MAPPER The new hardcorded group mapper allows adding a specific group to users brokered from an Identity Provider. USER SESSION NOTE MAPPER The new user session note mapper allows mapping a claim to the user session notes. LDAP FEDERATION LDAPS-ONLY TRUSTSTORE OPTION REMOVED LDAP option to use truststore SPI Only for ldaps has been removed. This parameter is used to select truststore for TLS-secured LDAP connection: either internal Keycloak truststore is picked (Always), or the global JVM one (Never). Deployments where Only for ldaps was used will automatically behave as if Always option was selected for TLS-secured LDAP connections. REMOVED OPENSHIFT INTEGRATION FEATURE The openshift-integration preview feature that allowed replacing the internal IdP in OpenShift 3.x with Keycloak was removed from Keycloak codebase into separate extension project. MIGRATION FROM 21.1 Before you upgrade remember to backup your database. If you are not on the previous release refer to for a complete list of migration changes. TRANSITION FROM JAVA EE TO JAKARTA EE Keycloak migrated its codebase from Java EE (Enterprise Edition) to its successor Jakarta EE, which brings various changes into Keycloak. We have upgraded all Jakarta EE specifications in order to support Jakarta EE 10, such as: * Jakarta Persistence 3.1 * Jakarta RESTful Web Services 3.1 * Jakarta Mail API 2.1 * Jakarta Servlet 6.0 * Jakarta Activation 2.1 Jakarta EE 10 provides a modernized, simplified, lightweight approach to building cloud-native Java applications. The main changes provided within this initiative are changing the namespace from javax.* to jakarta.*. It does not apply for javax.* packages provided directly in the JDK, such as javax.security, javax.net, javax.crypto, etc. You can be affected by these changes in your custom extensions, providers or JPA entities. UPGRADE TO QUARKUS 3 Keycloak upgraded to version 3 of the Quarkus Java framework. Quarkus 3 continues the tradition of propelling Java development by moving fast and providing a cutting-edge user experience with the latest technologies. It continues to improve overall performance and efficiency. Quarkus 3 is based on Jakarta EE 10, the same as Keycloak, creating smooth interoperability between them. In addition, it contains Eclipse MicroProfile 6, which aligns with Jakarta EE 10 Core Profile. The central part of the Quarkus 3 upgrade is built-in support for JPA 3.1 and Hibernate ORM 6. QUARKUS.HIBERNATE-ORM.* PROPERTIES NO LONGER WORKING For Quarkus 3, Hibernate ORM configurations must be specified in either the persistence.xml file or in Quarkus properties, but not in both places. Keycloak uses a persistence.xml file, therefore, it is no longer possible to override Keycloak’s JPA store configurations via Quarkus’ configuration properties for the default persistence unit whose names start with quarkus.hibernate-orm. UPGRADE TO HIBERNATE ORM 6 Keycloak now benefits from the upgrade to Hibernate ORM 6.2, which includes improved performance, better SQL, modern JDK support, and support for modern RDBMS features. The performance improvements primarily affect JDBC, HQL Translation, and Criteria Translation. If you have custom providers or JPA entities, these changes may affect you. We recommend reviewing the or the for more information. LEGACY PROMISE API REMOVED FROM KEYCLOAK JS ADAPTER The legacy Promise API methods have been removed from the Keycloak JS adapter. This means that calling .success() and .error() on promises returned from the adapter is no longer possible. Instead standardized Promise methods such as and should be used. Before migration: const keycloak = new Keycloak(); keycloak.init() .success(function(authenticated) { alert(authenticated ? 'authenticated' : 'not authenticated'); }).error(function() { alert('failed to initialize'); }); After migration: const keycloak = new Keycloak(); keycloak.init() .then(function(authenticated) { alert(authenticated ? 'authenticated' : 'not authenticated'); }).catch(function() { alert('failed to initialize'); }); Or alternatively, when using the keyword to unwrap these promises: const keycloak = new Keycloak(); try { const authenticated = await keycloak.init(); alert(authenticated ? 'authenticated' : 'not authenticated'); } catch (error) { alert('failed to initialize'); } EXPORT AND IMPORT PERFORM AN AUTOMATIC BUILD In previous releases, the export and import commands required a build command to be run first. Starting with this release, the export and import commands perform an automatic rebuild of Keycloak if a build time configuration has changed. When migrating existing scripts that run a build command first, migrate by adding the --optimized command line option to the export and import command to avoid Keycloak automatically re-building the image. Not adding the --optimized option in this might make Keycloak trigger a rebuild and revert to the default values, and then connecting to the database for export and import will not work. The following examples assume that runtime parameters like a database password are provided via a configuration file or an environment variable. Before migration: Running the build command before running the export command bin/kc.[sh|bat] build --db=postgres ... bin/kc.[sh|bat] export --dir &lt;dir&gt; After migration: Adding --optimized to the export command bin/kc.[sh|bat] build --db=postgres ... bin/kc.[sh|bat] export --optimized --dir &lt;dir&gt; After migration: Leveraging the auto-build functionality bin/kc.[sh|bat] export --dir &lt;dir&gt; --db=postgres ... NOTE When the auto-build runs, the build time options will be in effect for all subsequent commands that are started with the --optimized flag, including the start command. In previous releases the export and import commands allowed runtime parameters such as a database URL only in configuration files or environment variables. Starting with this release, those runtime parameters are now available on the command line as well. Use the --help option to find out about the supported parameters. RENAMED KEYCLOAK ADMIN CLIENT ARTIFACTS After the upgrade to Jakarta EE, artifacts for Keycloak Admin clients were renamed to more descriptive names with consideration for long-term maintainability. We still provide two separate Keycloak Admin clients, one with Jakarta EE and the other with Java EE support. We stopped releasing the org.keycloak:keycloak-admin-client-jakarta artifact. The default one for the Keycloak Admin client with Jakarta EE support is org.keycloak:keycloak-admin-client (since version 22.0.0). The new artifact with Java EE support is org.keycloak:keycloak-admin-client-jee. JAKARTA EE SUPPORT Before migration: &lt;dependency&gt; &lt;groupId&gt;org.keycloak&lt;/groupId&gt; &lt;artifactId&gt;keycloak-admin-client-jakarta&lt;/artifactId&gt; &lt;version&gt;21.0.0&lt;/version&gt; &lt;/dependency&gt; After migration: &lt;dependency&gt; &lt;groupId&gt;org.keycloak&lt;/groupId&gt; &lt;artifactId&gt;keycloak-admin-client&lt;/artifactId&gt; &lt;version&gt;22.0.0&lt;/version&gt; &lt;/dependency&gt; JAVA EE SUPPORT Before migration: &lt;dependency&gt; &lt;groupId&gt;org.keycloak&lt;/groupId&gt; &lt;artifactId&gt;keycloak-admin-client&lt;/artifactId&gt; &lt;version&gt;21.0.0&lt;/version&gt; &lt;/dependency&gt; After migration: &lt;dependency&gt; &lt;groupId&gt;org.keycloak&lt;/groupId&gt; &lt;artifactId&gt;keycloak-admin-client-jee&lt;/artifactId&gt; &lt;version&gt;22.0.0&lt;/version&gt; &lt;/dependency&gt; PASSTHROUGH PROXY MODE CHANGES Keycloak’s proxy configuration setting for mode passthrough no longer parses HTTP forwarding headers in the request, as when a proxy forwards an HTTPS connection in passthrough mode, a proxy is unable to add, remove or update HTTP headers. Installations that want the HTTP headers in the client’s request to be parsed should use the edge or reencrypt setting. See for details. CONSISTENT FALLBACK MESSAGE RESOLVING FOR ALL THEMES This change only may affect you when you are using realm localization messages. Up to this version, the resolving of fallback messages was inconsistent across themes, when realm localization messages were used. More information can be found in the following . The implementation has now been unified for all themes. In general, the message for the most specific matching language tag has the highest priority. If there are both a realm localization message and a Theme 18n message, the realm localization message has the higher priority. Summarized, the priority of the messages is as follows (RL = realm localization, T = Theme i18n files): RL &lt;variant&gt; &gt; T &lt;variant&gt; &gt; RL &lt;region&gt; &gt; T &lt;region&gt; &gt; RL &lt;language&gt; &gt; T &lt;language&gt; &gt; RL en &gt; T en. Probably this can be better explained with an example: When the variant de-CH-1996 is requested and there is a realm localization message for the variant, this message will be used. If such a realm localization message does not exist, the Theme i18n files are searched for a corresponding message for that variant. If such a message does not exist, a realm localization message for the region (de-CH) will be searched. If such a realm localization message does not exist, the Theme i18n files are searched for a message for that region. If still no message is found, a realm localization message for the language (de) will be searched. If there is no matching realm localization message, the Theme i18n files are be searched for a message for that language. As last fallback, the English (en) translation is used: First, an English realm localization will be searched - if not found, the Theme 18n files are searched for an English message. USERQUERYPROVIDER CHANGES UserQueryProvider interface was split into two. One is UserQueryMethodsProvider providing capabilities for querying users. Second one is UserCountMethodsProvider which provides capability for counting number of users in particular storage. Keycloak now has the ability to differentiate between user storage providers that can efficiently execute count queries and those that cannot. The UserQueryProvider interface still exists and extends both new interfaces. Therefore, there is no need for any modifications in the existing implementations of UserQueryProvider since it retains the same methods. LDAPSTORAGEPROVIDER SEARCH CHANGES Starting with this release Keycloak uses a pagination mechanism when querying federated LDAP database. Searching for users should be consistent with search in local database. Since this release LDAPStorageProvider implements only UserQueryMethodsProvider, not UserQueryProvider. DEPRECATION OF KEYCLOAK OPENID CONNECT ADAPTERS Starting with this release, we no longer will invest our time on the following Keycloak OpenID Connect Adapters: * Keycloak Wildfly OpenID Connect Adapter * Keycloak JEE Servlet OpenID Connect Adapter * Keycloak Spring Boot and Spring Security OpenID Connect Adapter This move is already reflected in our documentation and in our quickstart repository. Please, consider looking at the following references for more information: * * We recommend starting to look into moving your applications to the alternatives from the references above. Those adapters should not be available anymore in future releases. DEPRECATION OF KEYCLOAK JEE SAML ADAPTER The Keycloak JEE SAML Adapter has been discontinued, and we will no longer invest our time on its development following this release. The official adapter is now based on Jakarta and should be used as soon as you switch your applications to this technology. This change is already in our documentation and in our quickstart repository. For more information, please consider looking at the following references: * * If you cannot migrate your applications to Jakarta, you can still use the "legacy" SAML JEE adapter and still be able to integrate with future releases of the server. However, consider upgrading your applications as soon as possible because we are no longer providing support to JEE. CHANGES FOR OPENSHIFT-INTEGRATION FEATURE The preview feature openshift-integration was removed from Keycloak codebase and moved into separate extension. This includes moving of related providers such as custom client storage provider and token review endpoint for Openshift integration. If you used this feature, you should not use the openshift-integration feature anymore when starting Keycloak server and instead you need to deploy the JAR file from custom extension. You can check the and the instructions in it’s README file for how to deploy the extension to your Keycloak server. Note The Openshift extension is not officially supported and maintained by Keycloak team. You can use it only at your own risk. HTTP CHALLENGE FLOW REMOVED The built-in authentication flow http challenge was removed along with the authenticator implementations no-cookie-redirect, basic-auth, and basic-auth-otp. The http challenge authentication flow was also intended for Openshift integration and therefore it was removed along with other related capabilities as described above. Authenticator implementations were moved to the Openshift extension described in the previous paragraph. If you use the http challenge flow as a realm flow or as First Broker Login or Post Broker Login flow for any of your identity providers, the migration is not possible. Be sure to update your realm configuration to eliminate the use of the http challenge flow before migration. If you use the http challenge flow as Authentication Flow Binding Override for any client, the migration would complete, but you could no longer log in to that client. After the migration, you would need to re-create the flow and update the configuration of your clients to use the new/differentJson flow. REMOVING THIRDPARTY DEPENDENCIES The removal of openshift-integration allows us to remove few thirdparty dependencies from Keycloak distribution. This includes openshift-rest-client, okio-jvm, okhttp, commons-lang, commons-compress, jboss-dmr and kotlin-stdlib. This means that if you use any of these libraries as dependencies of your own providers deployed to Keycloak server, you may also need to copy those jar files explicitly to the Keycloak distribution providers directory as well. CONTEXT AND DEPENDENCY INJECTION NO LONGER ENABLED TO JAX-RS RESOURCES In order to provide a better runtime and leverage as much as possible the underlying stack, all injection points for contextual data using the javax.ws.rs.core.Context annotation were removed. The expected improvement in performance involves no longer creating proxies instances multiple times during the request lifecycle, and drastically reducing the amount of reflection code at runtime. If you are extending one of the following SPIs: * PolicySpi * AdminRealmResourceSpi * IdentityProviderSpi * RealmResourceSPI You should review your custom JAX-RS (sub)resources in order to obtain any contextual data as follows: KeycloakSession session = org.keycloak.common.util.Resteasy.getContextData(KeycloakSession.class); If you need access to the current request and response objects, you can now obtain their instances directly from the KeycloakSession: @Context org.jboss.resteasy.spi.HttpRequest request; @Context org.jboss.resteasy.spi.HttpResponse response; was replaced by: KeycloakSession session = // obtain the session, which is usually available when creating a custom provider from a factory KeycloakContext context = session.getContext(); HttpRequest request = context.getHttpRequest(); HttpResponse response = context.getHttpResponse(); In case you have no access to a KeycloakSession instance when invoking a JAX-RS resource method, you can obtain contextual data from the JAX-RS runtime as follows: KeycloakSession session = org.keycloak.common.util.Resteasy.getContextData(KeycloakSession.class); Additional contextual data can be obtained from the runtime through the KeycloakContext instance: KeycloakSession session = // obtain the session KeycloakContext context = session.getContext(); MyContextualObject myContextualObject = context.getContextObject(MyContextualObject.class); UPGRADING YOUR CUSTOM JAX-RS RESOURCES If you are extending the server’s REST APIs through the following SPIs: * PolicySpi * AdminRealmResourceSpi * IdentityProviderSpi * RealmResourceSPI You need to add an empty META-INF/beans.xml to the JAR file where your custom providers are packaged. Otherwise, they are not recognized by the server at runtime. You should also make sure your JAX-RS methods are declaring the expected media types for input and output by marking them with the @Consumes and @Produces annotations, respectively. DEPRECATED METHODS FROM DATA PROVIDERS AND MODELS In earlier versions of Keycloak, provider and model interfaces underwent a cleanup process that involved deprecating certain methods. In this release the methods were removed and some additional methods were deprecated. The Javadoc for these methods from Keycloak 21 included information about their corresponding replacements. * RealmModel#searchForGroupByNameStream(String, Integer, Integer) was removed. * UserProvider#getUsersStream(RealmModel, boolean) was removed. * UserSessionPersisterProvider#loadUserSessions(int, int, boolean, int, String) was removed. * Interfaces added for Streamification work were removed. Such as RoleMapperModel.Streams and similar. * Streams interfaces in federated storage provider classes were deprecated. * KeycloakModelUtils#getClientScopeMappings was removed. * Deprecated methods from KeycloakSession were removed. * UserQueryProvider#getUsersStream methods were removed. MULTIPLE KEYCLOAK INSTANCES Multiple Keycloak CRs may be created in the same namespace and will be managed independently by the operator. To allow for this StatefulSets created by older versions of the operator must be re-created. This will happen automatically when the operator is upgraded and lead to small amount of downtime. K8S.KEYCLOAK.ORG/V2ALPHA1 CHANGES The condition status field was changed from a boolean to a string for conformance with standard Kubernetes conditions. In the CRD it will temporarily be represented as accepting any content, but it will only ever be a string. Please make sure any of your usage of this field is updated to expect the values "True", "False", or "Unknown", rather than true or false. KEYCLOAK SUPPORTS IPV4/IPV6 DUAL STACK Keycloak supports the IPv4/IPv6 dual stack and can be accessible by default via the IPv4 and IPv6 addresses. In the older versions of Keycloak, the default approach was to use only IPv4 addresses. For more details, see . ALL RESOLVED ISSUES NEW FEATURES * Require user to agree to 'terms and conditions' during registration keycloak * Securing credentials/passwords not possible with Quarkus distribution keycloak dist/quarkus * Enable Horizontal Pod Autoscaling for Keycloak deployed with the new Operator keycloak * Support OpenJDK 19 keycloak * Hostname debug tool keycloak dist/quarkus * Add Keycloak Keystore Vault implementation keycloak dist/quarkus * Claim to User Session Note Idp Mapper keycloak oidc * Supporting reference access/refresh tokens keycloak * Allow changing admin console logo and favicon from theme.properties keycloak * Group attribute query is missing QueryParams in java admin client keycloak admin/client-java * SSSD integration in Quarkus distribution keycloak * Add support to the Operator for setting default labels on Keycloak pods keycloak operator * Support for JWE IDToken and UserInfo tokens in OIDC brokers keycloak identity-brokering ENHANCEMENTS * Update QuickStarts documentation to Quarkus distribution keycloak-quickstarts * Re-enable test that where disabled when updating test for the Quarkus dist keycloak-quickstarts * Nashorn dependency no longer needed in quickstarts keycloak-quickstarts * Doublecheck "provider" quickstarts with quarkus3 based Keycloak distribution keycloak-quickstarts * user-storage-* provider quickstarts keycloak-quickstarts * Event listener sysout quickstart keycloak-quickstarts * Event store mem quickstart keycloak-quickstarts * Extend-account-console quickstart keycloak-quickstarts * Remove keycloak-remote profile keycloak-quickstarts * Clarification on user registration and identity brokering keycloak-documentation * Reset Credentials Flow does not delete existing OTP keycloak authentication * Remove any unnecessary dependency from distribution keycloak dist/quarkus * OTP base32 decode improvements keycloak * Expose deployment errors in the status field of Keycloak CR keycloak operator * Support multiple KC instances in a single namespace keycloak operator * Use SchemaSwap instead of shell script for Realm CRD generatio keycloak operator * Use Quarkus JOSDK to generate CSV for OLM in the operator keycloak operator * Non ASCII characters in TOTP secret not supported in 2FA configurations keycloak authentication * Add support to indicate desired locale on init func with onLoad: 'login-required' options keycloak adapter/javascript * Add a name to the keycloak port in the service keycloak * Operator CRD status incompatible with kstatus keycloak operator * Addition of Custom User Attribute Filter to Users API Count Endpoint keycloak * Enable IPv6 dualstack support by default keycloak dist/quarkus * Clean `RealmProvider` from methods from other areas keycloak storage * Remove methods for old default roles approach keycloak storage * Back to Application link should be client specific with the UPDATE_EMAIL feature keycloak * Support configurable custom Identity Providers keycloak * Customize log messages for user storage LDAP configuration in KC shown in admin UI keycloak * Update migration guide with the changes that need to be done for developers using JAX-RS in their extensions keycloak * Update Datastore provider to contain full data model keycloak storage * "Failed to add user 'admin' ..." should not be an ERROR keycloak dist/quarkus * support parameters like "uri" and "matchingUri" in the UMA grant token endpoint keycloak * Group Attribute Search Erroneously returns when searching for nested group keycloak storage * Operator Support for missing leading slash and present trailing slash in `http-relative-path` keycloak operator * Add "Enable new user after creation" option for Active Directory keycloak * Refine the set of RPMs included in the keycloak container image keycloak dist/quarkus * Minimize the RPM content of the Operator container keycloak operator * CRDB optimization: Optimize selects targeting the primary key or unique keys keycloak storage * security enhancement : representation of admin events &amp;amp; credentials keycloak * Migrate realms if configured to use RH-SSO themes keycloak * Javascript example not printing errors keycloak docs * Allow pre-filled GitHub issue forms via links from docs keycloak docs * Add missing Spanish translations for login keycloak translations * Add `lang` attribute to HTML tag of UIs keycloak account/ui * Only add Access properties on groups, if the fine grain feature is on keycloak * Upgrading to Infinispan 14.0.8 keycloak * Conditional login through identity provider keycloak * account console v3 theme.properties customizations keycloak * Correct formatting in Server Developer guide keycloak * Adhere to HTML standard when using `ul`-element keycloak * SSSD documentation updated for quarkus distribution keycloak * SSSD testing with GH actions keycloak * UserPropertyMapper generated exceptions on mapping keycloak * Upgrade JNA library keycloak * Client executor for reject implicit grant when enabled for clients keycloak oidc * Upgrade owasp html sanitizer to newest version keycloak * Look ahead window setting in OTP policy is not accurate keycloak admin/ui * Enable `simple-cache` for `local-cache` keycloak * Move openshift client integration to separate extension keycloak core * Move http-challenge authentication flow and the related authenticators to the extension keycloak authentication * Also run Cypress tests on Firefox keycloak testsuite * Allow custom annotation in Ingress keycloak * Show warning message when overriding build options during starts keycloak * FAPI 2.0 security profile - not allow an authorization request whose parameters were not included in PAR request keycloak * Increase the length of password hash iterations password-policy input in admin ui keycloak admin/ui * Removing unnecessary message from main command help text keycloak * FAPI 2.0 security profile - not allow an authorization request whose parameters were not included in Request Object pushed to PAR request keycloak * Add Hardcoded Group mapper to Identify Provider configuration keycloak * Ability for users to view credentials without manage user permissions keycloak admin/api * Update docs (and maybe tooltips) for timeout changes keycloak docs * Improve start page on the account ui keycloak account/ui * Update securing_applications guide for latest adapter changes (community) keycloak docs * Allow any JGroups stack with --cache-stack keycloak * Support for the `locale` user attribute keycloak * Add missing Polish translations keycloak translations * Remove adapters from product documentation keycloak docs * Upgrade to Quarkus 3.2.0.Final keycloak * Add `iat` claim to JWT that is passed to CIBA HttpAuthenticationChannel keycloak * When essential claim check fails the error message should provide detailed information keycloak * Enable publishNotReadyAddresses for discovery service keycloak BUGS * Quickstarts for action-token-authenticator / action-token-required-action not working keycloak-quickstarts * Legacy quickstart tests are failing since quarkus3 upgrade keycloak-quickstarts * Tests does not work on OpenJDK 17 for quickstarts keycloak-quickstarts * Refresh token with offline_access scope affected by session idle/session max keycloak oidc * LDAPS Bind test fails with SSLHandshakeException while LDAP connection test works keycloak ldap * Unable to add more than 6 acceptable AAGUIDs for WebAuthn keycloak authentication/webauthn * User search with LDAP federation not consistent keycloak ldap * SLO and ACS Binding are linked with AuthnRequest Binding in SAML Identity Broker Metadata keycloak saml * SSSD Federation fails with NPE after upgrade keycloak authentication * Negative refresh token expiration (exp timestamp in the past) keycloak oidc * KEYCLOAK-17116 Copy of Browser Flow overrides an original one keycloak authentication * Trust Store hostname-verification-policy=ANY seems to be ignored keycloak docs * Clearify the use of `db-url-properties` keycloak docs * [keycloak-js] multiple init call with onload option as check-sso cause redirects keycloak adapter/javascript * importing bin/kc.[sh|bat] import --file doesn't work when using external database keycloak dist/quarkus * MigrationTest for KC 17 failures in the pipeline keycloak testsuite * RecoveryAuthnCodesAuthenticatorTest failures in the pipeline keycloak testsuite * Switching Locale after Completing an admin triggered required action yields an error keycloak authentication * Client-secret with special character (+) for authorization is failing in 19.0.2 keycloak oidc * ID token is not including roles keycloak oidc * Realm update fails when realm has many Identity Providers configured and saves rep. with Admin Events keycloak admin/api * Client session lifespan doesn't consider user session lifespan keycloak authentication * User Session Note Mapper no longer adds IMPERSONATOR_USERNAME as SAML attribute keycloak saml * Able to modify built-in flow keycloak admin/api * Unable to perform export when server was started with new storage keycloak dist/quarkus * Realm localization: Inconsistent message resolving regarding language fallbacks for different themes keycloak core * Incorrect Signature algorithms presented by Client Authenticator keycloak oidc * Keycloak Export only accept H2 datase-URL (Datasource: URL format error; must be jdbc:h2 ... but is jdbc:mariadb: ...) keycloak dist/quarkus * SSSD User Federation dissapeared in 20.0.1/20.0.2 keycloak authentication * Set OpenShift as a "Social Identity Provider" cannot work keycloak identity-brokering * Single client export bug keycloak docs * Hibernate 6 upgrade: Warning SqmDynamicInstantiation about dynamic Map instantiation keycloak storage * Quarkus 3: RealmModelTest.testRealmLocalizationTexts fails keycloak testsuite * Setting user password and entering "password confirmation" first leads to blocking of "save" keycloak admin/ui * Impossible to update a federated user credential label keycloak admin/api * Update documentation around `View all users` behavior in the new admin console keycloak docs * upgrading from v18.0.2 to 19.0.3 or 20.0.3 fails with ERROR duplicate key value violates unique constraint "constraint_3c" keycloak core * Theme &amp;amp; Provider folder empty in KeyCloak 20.0.3 keycloak docs * New Referrer-policy breaks cross-origin SPIdP (KC) keycloak saml * Make LDAP `searchForUsersStream` consistent with other storages keycloak storage * javax.net.ssl.SSLException exceptions because org.keycloak.adapters.HttpClientBuilder ignores connectionTTL setting keycloak oidc * Error updating old version (Keycloak 8) to Keycloak 20. NPE thrown due the realm.getDefaultRole() keycloak core * Error: realms.removeSession wrong generic type keycloak admin/client-js * Incorrect Url on Keycloak Health - Liveness and Readiness, no Startup Probes keycloak operator * `JpaUserProvider` count methods are inconsistent with `searchForUser`'s param filter handling keycloak storage * Memory issue with PathCache when running the traffic keycloak authorization-services * Report an issue link points to Jira instead of GHI keycloak docs * Priority not sent to server when adding new RSA key provider keycloak admin/ui * Server Deployment documentation is not updated to Quarkus keycloak docs * Slow Query Caused By Composite Indexes Order On Broker Link Table keycloak storage * User ID is ignored in partial import keycloak import-export * Hibernate 6: Entity in Key not returned when querying keycloak storage * Facebook identity provider not working keycloak identity-brokering * SignatureProvider not showing up in the Default Signature Algorithm list keycloak admin/ui * Custom ResetCredentialEmail does not work after upgrade to Keycloak 21 keycloak core * Account Console II doesn't remove TOTP from UserStorage keycloak account/api * A way to override internal SPI after KC 21 keycloak core * Custom User Storage Provider doesn't look up users after saving changes keycloak admin/ui * Gzip cache is only invalidated upon Keycloak version changes keycloak core * AlreadyLoggedIn when impersonating a user in a SAML client keycloak core * Operator restarts occasionally result in recreation of managed keycloak Statefulset Pods keycloak operator * Email settings erased after any change on realm settings keycloak admin/ui * Documentation for User Storage Spi is incorrect keycloak storage * Custom providers are not loaded properly in KC21 keycloak core * Custom SignatureProviderFactory is not working as expected after Keycloak 21 upgrade keycloak core * Testsuite must rely on IDs from Keycloak keycloak testsuite * Support for realm-less entities in login failures keycloak storage * NPE when updating a subflow in an authentication flow keycloak admin/api * Incorrect HTTP status reported when DNS resolver is not available (and DB connection unavailable due to that) keycloak core * Admin UI does not respect default values for custom authenticator configurations keycloak admin/ui * Create a Client Policy on realm with client-roles or client-scopes condition raises an expection on the Client details keycloak admin/ui * Test app is not functioning - https://www.keycloak.org/app/ keycloak docs * Account v3 - account console link redirect to master realm keycloak account/ui * New Flow created for Post Login Flow IDP not mark "Used by" at Flows keycloak admin/ui * Logout redirect URL truncated since v20 keycloak oidc * User search with more than two keywords returns empty list keycloak storage * Default Roles show all roles if "Hide inherited roles" is not checked keycloak admin/ui * Conditional user attribute authenticator does not match the joined groups keycloak oidc * authenticator javaScript Provider always failed the login, user context is lost and break the login keycloak core * Flaky test: org.keycloak.testsuite.adapter.servlet.OfflineServletsAdapterTest#testServlet keycloak ci * Cannot find @Generated annotation for ServicesLogger keycloak dependencies * Update passthrough behavior and docs keycloak dist/quarkus * Conditionally build WildFly adapters for our testsuite keycloak testsuite * Custom theme - url.resourcesCommonPath references wrong theme keycloak admin/api * FederatedUserLink always points to LDAP keycloak admin/ui * Duplicated serverPrincipal property in LDAPStorageProviderFactory keycloak storage * Unable to template emails in EventListenerProvider (No realm in provided KeycloakSession) keycloak authentication * Support for non-XA databases keycloak storage * User defined message bundles do not apply correctly to Admin Console keycloak admin/ui * Valid redirect URI &amp;amp; web origin input fields display when "Standard flow" is disabled keycloak admin/ui * Flaky test: org.keycloak.testsuite.model.session.OfflineSessionPersistenceTest#testLazyClientSessionStatsFetching keycloak ci * Failing ExternalLinks tests for old Keycloak JIRA Links keycloak docs * Quarkus 3 build properties break product build keycloak dist/quarkus * Flaky test: org.keycloak.testsuite.model.infinispan.CacheExpirationTest#testCacheExpiration keycloak ci * When choosing resources in scope-based permission, multiple resource can be selected but only one will be visable keycloak admin/ui * Additional Provider Info only shows at end of list not below provider keycloak admin/ui * Keycloak-js crasher: Missing null checks. Websites that have inline scripts without a src attribute as src attributes are not required. keycloak adapter/javascript * Error 500 after signin to admin console: NullPointerException keycloak core * WebAuthn test fails in the GHA keycloak testsuite * keycloak-js-admin-client and keycloak-js-adapter do not build when a maven proxy is configured keycloak * Fix User Federation tests after Q3 upgrade keycloak testsuite * Servlet tests for JBoss-based adapters with TLS are broken keycloak testsuite * Productization issue related to JNA upgrade keycloak dependencies * SAML error not shown to user keycloak admin/ui * ClientScope changes don't invalidate the realm cache keycloak storage * Administration / Keycloak Admin REST API documentation can no longer be generated keycloak docs * Avoid NPE while fetching offline sessions keycloak storage * Changing the email address has no impact at username regardless "Email as username" toggle keycloak user-profile * Fix tests related to file storage keycloak testsuite * Admin UI - unable to load user's groups when large number of groups defined for the realm keycloak admin/ui * When user federation is enabled, admin console user search doesn't show search field keycloak admin/ui * Enabled User Event Types not visible when "Save events" disabled. keycloak admin/ui * User events settings - "Save events" toggle doesn't always activate Save button. keycloak admin/ui * Ensure proper escaping for LDAP keycloak storage * For versions &gt; 18.x.x client mapper is not able to override "name" for OpenID tokens keycloak oidc * [Declarative User Profile] Optional attributes become required keycloak admin/ui * `register-node-at-startup` in EAP Client Adapter eventually causes "java.lang.OutOfMemoryError: unable to create native thread keycloak adapter/jee * Identity providers initialization has to use models keycloak storage * Update example custom cache configuration for v&gt;21 keycloak docs * keycloak-admin-client does not url-encode client id and secret for basic auth as defined in RFC6749 keycloak admin/client-js * Introduced additional dependencies in the testsuite keycloak testsuite * Moving a group to root loses all its members keycloak admin/ui * FAPI 2.0 security profile - Reject Implicit Grant executor does not return an appropriate error keycloak oidc * Add back examples for Kubernetes and Openshift to the quickstarts keycloak core * Reset password does not show option to sign out from other devices keycloak authentication * Could not process response from SAML identity provider because "this.text" is null keycloak identity-brokering * Userinfo endpoint doesn't accept charset keycloak oidc * Missing SAML Allow ECP Flow option keycloak admin/ui * Selecting one mapper and switch page select them all keycloak admin/ui * REST API Documentation ref wrong keycloak docs * Realm export performance heavily depends on the amount of users per file keycloak import-export * Keycloak deployed via new keycloak-operator triggers OpenShift alert `IngressWithoutClassName` keycloak operator * Denial of Service/100% CPU usage: CRLUtils in infinite loop if more than one CRL list is used from different CAs keycloak core * Keycloak erases form data on validation when `login_hint` is present keycloak account/ui * SEND_RESET_PASSWORD event is not stored keycloak admin/api * Mappers tab is not reachable on identity provider settings keycloak admin/ui * Webauthn signature algorithms are improperly encoded as strings keycloak authentication/webauthn * There is no server side pagination for sessions keycloak admin/ui * Private key JWT authentication no longer works on Keycloak 21 keycloak authentication * Empty shortVerificationUri not the same with default (null) value keycloak authentication * Session cross-reference / transaction mismatch keycloak core * Emails with non-ascii characters are not allowed since v21.0.0 keycloak user-profile * Flaky test: org.keycloak.operator.testsuite.integration.ClusteringTest#testKeycloakScaleAsExpected keycloak operator * Keycloak's default http client doesn't check HTTP response code keycloak core * keycloak-server from testsuite won't start keycloak testsuite * Partial Import is not working for resource Type in keycloak 21.1.1 keycloak import-export * Jump links render wrong on small screens keycloak admin/ui * Performance degradation when upgrading from RHSSO 7.6 to KC22 caused by TLSv1.3 processing keycloak dist/quarkus * Avoid loading classes and resources from new store if legacy is enabled keycloak storage * NPE when shutting down JPA after a failed initialization keycloak storage * processGrantRequest in TokenEndPoint uses new TokenManager instead of this.tokenMananager keycloak oidc * Custom User Storage Provider gets disabled when saved keycloak admin/ui * Role details not visible unless the user has "View Realm" enabled keycloak admin/ui * Group list isn't filtered based on permission like user lists keycloak admin/fine-grained-permissions * Service Account Impersonation fails and results in weird browser state keycloak core * Client scopes mapping not available for users with "view-clients" and "query-clients" keycloak admin/ui * custom user storage provider update in admin-ui disables it, and stores value “t” as enabled keycloak admin/ui * GroupResource POST /children cannot update existing subgroups keycloak admin/api * Broken Links / Redirects Issues in Docs - 2023-06-27 keycloak docs * UserSessionConcurrencyTest#testConcurrentNotesChange fails intermittently keycloak testsuite * UserSessionProviderModelTest#testRemoteCachesParallel sessions are not removed after the test keycloak testsuite * Keycloak Docs for Native App Redirect URI Should Recommend the IP literal keycloak docs * 3rd party check in iframe not working anymore in safari and keycloak 21.1.2 keycloak oidc * [docs] External Links Errors - saml.xml.org http -&gt; https redirect keycloak docs * List of tested database in docs doesn't match pom.xml keycloak docs * NPE in Edit Identity Provider Mapper on second Save keycloak admin/ui * SSSD users with capitals in the email cannot login to keycloak keycloak core * JavascriptAdapterTest is broken due to the multiple initialization of JS adapter keycloak testsuite * Nexus staging plugin failing after Java 11 deprecation keycloak ci * Cookie error on second browser tab keycloak core * Quarkus 3.2 changed the property for quarkus.transaction-manager.object-store-directory keycloak dist/quarkus * Wrong message for sync actions on LDAP role mapper keycloak admin/ui UPGRADING Before you upgrade remember to backup your database and check the for anything that may have changed.</content><dc:creator /></entry><entry><title type="html">Client-side Prometheus Dashboards with Dashbuilder</title><link rel="alternate" href="https://blog.kie.org/2023/07/client-side-prometheus-dashboards-with-dashbuilder.html" /><author><name>William Siqueira</name></author><id>https://blog.kie.org/2023/07/client-side-prometheus-dashboards-with-dashbuilder.html</id><updated>2023-07-10T17:08:24Z</updated><content type="html">is a tool for creating dashboards. It runs entirely on client, hence no installation is required, users can use the to create dashboards. We already talked about . At that time we had to manually parse the Prometheus response. In Dashbuilder 0.30.0 we made huge advancements for Prometheus which I will share in this post. WHY USING DASHBUILDER? Here are the reasons why you should consider Dashbuilder as an alternative to monitor Prometheus metrics: * Lightweight: The final dashboard version usually takes less then 100mb of memory; * Zero costs: It runs entirely on client-side, which means that no backend installation is required * Embeddable: Dashbuilder can be embed in other applications. Just download the bundle from the NPM package and put Dashbuilder in an iframe in your application and the dashboard can be configured using query parameter * Tooling: The is available for free and no login is required, just access it and start editing. There’s also a . * Open Source: Dashbuilder is part of , which is open source and uses HOW TO USE DASHBUILDER WITH PROMETHEUS The key is in the dataset. A dataset is where Dashbuilder gets the source of data for its displayers (blocks of a dashboard) and internally we have a special dataset type for Prometheus response queries. Once we have datasets we can then display the content in blocks called displayer. A basic dashboard definition is as follows: datasets: - uuid: up url: http://localhost:9090/api/v1/query?query=up type: prometheus pages: - components: - settings: lookup: uuid: up It renders the query up in a table For a real world dashboard we almost never have a single dataset – we observe different metrics and put all together in a dashboard to monitor different metrics, so let’s create a global dataset and separate the parts of the URL in dataset properties: properties: prom_url: http://localhost:9090 global: dataset: url: ${prom_url} type: prometheus path: /api/v1/query datasets: - uuid: metric_up query: query: up pages: - components: - displayer: lookup: uuid: metric_up See the explanation for each part of the code: Now that we know the basic about dashboards, let’s explore a more complex to monitor JVM using Micrometer metrics. JVM MICROMETER PROMETHEUS DASHBOARD PROPERTIES This dashboard can be configured to any Prometheus installation that has Micrometer metrics. Users can setup a global filter for all metrics and the refresh time for all displayers. properties: ### User properties (you can modify this) prometheus_url: http://localhost:9090 job: "quarkus-app" refresh_seconds: 30 period: 15m window: 30s # style subTitleStyle: "padding: 5px; background-color: #F1F1F1; font-size: medium; font-weight: bolder; margin: 5px" titleStyle: "font-size: x-large; margin: 10px; font-weight: bold" ### Internal Properties time_window: "[${period}:${window}]" global_filter: 'job="${job}"' GLOBAL SETTINGS Following the properties we declare the global settings which includes the datasets, displayers and the mode (dark) and we set the flag allowUrlProperties, so the properties can be modified using query parameters. All the datasets will share the same URL, type, path. For the displayers we have a common template for the cards (see property html/html), the refresh interval and a shared chart configuration. global: mode: dark dataset: url: ${prometheus_url} type: prometheus path: /api/v1/query cacheEnabled: true refreshTime: "1second" displayer: refresh: interval: ${refresh_seconds} extraConfiguration: &gt;- { "xAxis": { "splitNumber": 3 }, "title": { "textStyle" : { "fontSize" : 15 } } } chart: resizable: true height: 180 zoom: true grid: x: false margin: bottom: 20 top: 35 legend: show: false html: html: &gt;- &lt;div id="${this}" class="card-pf card-pf-aggregate-status" style="background-color: ${bgColor}; width: 90%; height: 58px;margin: 10px; border-radius: 10px;"&gt; &lt;p style="font-weight: 600; font-size: small" id="${this}Title"&gt;&lt;em id="${this}Icon" class=""&gt;&lt;/em&gt; ${title}&lt;/p&gt; &lt;h2 style="margin: 5px; font-weight: 600; font-size: large" id="${this}Value"&gt;${value} &lt;span id="${this}Suffix" class=""&gt;&lt;/span&gt;&lt;/h2&gt; &lt;/div&gt; The datasets declaration contains only the ID and the query, all the other properties are inherited from the global dataset configuration. Notice that the query must include the properties global_filter and time_window (for timeseries). datasets: ## cards Datasets - uuid: uptime query: query: process_uptime_seconds{${global_filter}} - uuid: start_time query: query: process_start_time_seconds{${global_filter}} - uuid: heap_used query: query: sum(jvm_memory_used_bytes{${global_filter},area="heap"})*100/sum(jvm_memory_max_bytes{${global_filter},area="heap"}) - uuid: system_cpu_usage query: query: system_cpu_usage{${global_filter}} ## TIMESERIES datasets # Memory - uuid: heap_used_bytes query: query: jvm_memory_used_bytes{${global_filter}, area="heap"}${time_window} - uuid: nonheap_used_bytes query: query: jvm_memory_used_bytes{${global_filter}, area="nonheap"}${time_window} - uuid: used_bytes_total query: query: sum by (instance) (jvm_memory_used_bytes{${global_filter}})${time_window} # Threads - uuid: threads_states query: query: jvm_threads_states_threads{${global_filter}}${time_window} - uuid: live_threads query: query: jvm_threads_live_threads{${global_filter}}${time_window} - uuid: daemon_threads query: query: jvm_threads_daemon_threads{${global_filter}}${time_window} # GC - uuid: gc_pause_sum query: query: jvm_gc_pause_seconds_sum{${global_filter}}${time_window} # System - uuid: open_files query: query: process_files_open_files{${global_filter}}${time_window} - uuid: system_cpu query: query: system_cpu_usage{${global_filter}}${time_window} PAGES For this dashboard we have a grid of 3×4. The titles you see in the image are actually an embed page on a collapsible panel. DISPLAYERS To actually show the data we use Displayers. In this page we have two displayers: METRIC (cards) and TIMESERIES. METRICS A metric displayer can display a single value using an HTML template (see global displayer). It is also possible to use Javascript to give some action to the card or we can apply Javascript to modify the card value using column settings. See for example the card Start Time, it uses the value from dataset start_time. - displayer: type: METRIC general: title: Start Time columns: - id: value expression: &gt;- const d = new Date(value * 1000); const year = d.getFullYear(); const day = d.getDay(); const month = d.getMonth(); const hour = d.getHours(); const minute = ${d.getMinutes()}.padStart(2, 0); const second = ${d.getSeconds()}.padStart(2, 0); ${hour}:${minute}:${second} ${day}/${month}/${year} lookup: uuid: start_time group: - functions: - source: value TIMESERIES For timeseries displayers we must provide 3 columns: series, timestamp and value. Each distinct value of column series will be translated to a line in the timeseries chart. See for the example the Heap Memory Used Bytes timeseries, it uses the dataset heap_used_bytes. - displayer: type: TIMESERIES general: title: Heap Memory Used Bytes chart: margin: left: 100 lookup: uuid: heap_used_bytes group: - functions: - source: id - source: timestamp - source: value We could continue using Dashbuilder features to improve this dashboard: Filter and a panel to modify the properties are possible improvements, but we will stop with this simpler version. CONCLUSION The new features makes Dashbuilder a viable lightweight alternative to monitor Prometheus metrics. Stay tuned for new Dashbuilder features and articles! The post appeared first on .</content><dc:creator>William Siqueira</dc:creator></entry><entry><title type="html">Securing WildFly Management Console with Keycloak</title><link rel="alternate" href="https://www.mastertheboss.com/keycloak/securing-wildfly-management-console-with-keycloak/" /><author><name>F.Marchioni</name></author><id>https://www.mastertheboss.com/keycloak/securing-wildfly-management-console-with-keycloak/</id><updated>2023-07-10T10:05:54Z</updated><content type="html">WildFly 29 introduces the ability to secure WildFly Management Console with KeyCloak OpenID Connect Clients. In this article we will go through the steps you need to configure WildFly elytron-oidc-client subsystem and the Keycloak Realm. By the end of it, you will learn how to secure your WildFly Management Console with Keycloak OpenID Connect. Prerequisites ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry></feed>
